<!DOCTYPE HTML>
<html lang="en">

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-E00L9PT3V9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-E00L9PT3V9');
  </script>
  <title>Haoming Cai</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="Haoming Cai" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="http://localhost:4000/">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  
  <style>
    body {
      background-color: #000000; /* New background color */
    }
  </style>

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Haoming Cai 
                <h11>/haʊˈmɪŋ tsaɪ/</h11>
              </h1>
              
              <p>I am a thrid-year CS PhD student @ <a href="https://www.cs.umd.edu/">CS Department</a> of University of Maryland, College Park, advised by Professor <a href="https://www.cs.umd.edu/people/metzler">Christopher Metzler</a>.
              </p>
              <p>
                Previously, I had a wonderful journey (2020-2022) in <a href="https://xpixel.group/index.html">X-Pixel</a> with my supervisor Prof. <a href="https://scholar.google.com/citations?user=OSDCB0UAAAAJ&hl=en&oi=ao">Dong Chao</a> (Shanghai AI Lab) and mentor Dr.<a herf="https://scholar.google.com/citations?user=uMQ-G-QAAAAJ&hl=en"> Gu Jinjin</a> (Univeristy of Sydney).
              </p>
              <p>
                Contact : hmcai@umd.edu / <del>helmut.choy@gmail.com</del> / <del>haomingcai@link.cuhk.edu.cn</del>
              </p>

              <p>
                My CV : <a href="https://drive.google.com/file/d/1Cadhu233QjHwGMO5RzZb8Fw0YbSxdrPq/view?usp=sharing"><b><u>PDF</u></b></a>
              </p>

              <p style="text-align:center">
                <a href="https://github.com/HaomingCai">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=mePn76IAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.flickr.com/photos/201416778@N04/">Flickr</a> &nbsp;/&nbsp;
              </p>

            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:65%" alt="profile photo" src="images/profile.jpg">
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%">
              <h2>Research Interest</h2>
              <p2>
                - My research centers on the convergence of <u>Computational Photography, Gen AI and Low-level Vision</u>. I aim to synergize computational imaging techniques with advanced back-end processing algorithms to enhance the perceptual quality of human experiences on mobile and edge devices.
              </p2>
              <hr>
              <quote>
                Sometimes Science Is More Art Than Science -- Rick Sanchez
              </quote>
              
            </td>
          </tr>
        </table>

<!-- 
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </table> -->










        <!-- <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h25>3D Reconstruction in Computational Photography (2023-Now)</h25>
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </table> -->







      
        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h25>Seeing, Tracking, and Reconstruction (2D & 3D) Under Challenging Imaging Conditions (2023-Now)</h25>
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_23_ConVRT.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Temporally Consistent Atmospheric Turbulence Mitigation with Neural Representations</h3>
              <br>
              <strong>Haoming Cai*</strong>, Jingxi Chen*, Brandon Y. Feng, Weiyun Jiang, Mingyang Xie, Kevin Zhang, Cornelia Fermuller, Yiannis Aloimonos, Ashok Veeraraghavan, Christopher Metzler.

              <br>
              <em><strongvenue>NeurIPS'24</strongvenue></em>
              <br>
              
              
              
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_24_Flash.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Flash-Splat: 3D Reflection Removal with Flash Cues and Gaussian Splats</h3>
              <br>
              Mingyang Xie*, <strong>Haoming Cai*</strong> , Sachin Shah, Yiran Xu, Brandon Y. Feng, Jia-bin Huang, Christopher Metzler

              <br>
              <em><strongvenue>ECCV'24</strongvenue></em>
              <br>
              
              
              
              
              
              
              <a href="https://flash-splat.github.io/">website</a> /
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_23_PSF.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>CodedEvents: Optimal Point-Spread-Function Engineering for 3D-Tracking with Event Cameras</h3>
              <br>
              Sachin Shah, Matthew Albert Chan, <strong>Haoming Cai</strong>, Jingxi Chen, Sakshum Kulshrestha, Chahat Deep Singh, Yiannis Aloimonos, Christopher Metzler.

              <br>
              <em><strongvenue>CVPR'24</strongvenue></em>
              <br>
              
              
              
              
              
              
              
              <p></p>
              <p>This paper explores PSF engineering for neuromorphic event cameras, designing optimized masks for superior 3D point localization and tracking.</p>

            </td>
          </tr>
          
          
          
          
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_23_Snow.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Snow Removal in Video: A New Dataset and A Novel Method</h3>
              <br>
              Haoyu Chen, Jingjing Ren, Jinjin Gu, Hongtao Wu, Xuequan Lu, <strong>Haoming Cai</strong>, Lei Zhu

              <br>
              <em><strongvenue>ICCV'23</strongvenue></em>
              <br>
              
              <small><a href="https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Snow_Removal_in_Video_A_New_Dataset_and_A_Novel_ICCV_2023_paper.html">arxiv</a></small>/
              
              
              
              <a href="https://github.com/haoyuc/VideoDesnowing">code</a> /
              
              
              
              
              <a href="https://haoyuchen.com/VideoDesnowing">website</a> /
              
              
              <p></p>
              <p>This paper presents a new deep learning framework for removing snow from videos, featuring a high-quality dataset and innovative modules for effective snow removal, outperforming existing methods.</p>

            </td>
          </tr>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </table>




        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h25>Image/Video Generation through Diffusion Model (2023-Now)</h25>
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_24_Event.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>TimeRewind: Rewinding Time with Image-and-Events Video Diffusion</h3>
              <br>
              Jingxi Chen, Brandon Y. Feng, <strong>Haoming Cai</strong>, Mingyang Xie, Christopher Metzler, Cornelia Fermuller, Yiannis Aloimonos

              <br>
              <em><strongvenue>Under Review - 2024</strongvenue></em>
              <br>
              
              
              
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </table>






        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h25>Image Metric Design Inspired by Human Visual System (2020-Now)</h25>
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_23_OBIQA.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Assessor360: Multi-sequence Network for Blind Omnidirectional Image Quality Assessment</h3>
              <br>
              Tianhe Wu, Shuwei Shi, <strong>Haoming Cai</strong> , Mingdeng Cao, Jing Xiao, Yinqiang Zheng, Yujiu Yang

              <br>
              <em><strongvenue>NeurIPS'23</strongvenue></em>
              <br>
              
              <small><a href="https://arxiv.org/abs/2305.10983">arxiv</a></small>/
              
              
              
              <a href="https://github.com/TianheWu/Assessor360">code</a> /
              
              
              
              
              <a href="https://github.com/TianheWu/Assessor360">website</a> /
              
              
              <p></p>
              <p>Current omnidirectional image quality assessment lacks observer browsing modeling. We propose Assessor360, a novel multi-sequence network for BOIQA derived from realistic multi-assessor ODI quality assessment</p>

            </td>
          </tr>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_20_PIPAL.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Pipal: a large-scale image quality assessment dataset for perceptual image restoration</h3>
              <br>
              Jinjin Gu, <strong>Haoming Cai</strong>, Haoyu Chen, Xiaoxing Ye, Jimmy S Ren, Chao Dong.

              <br>
              <em><strongvenue>ECCV'20</strongvenue></em>
              <br>
              
              <small><a href="https://arxiv.org/pdf/2007.12142">arxiv</a></small>/
              
              
              
              
              
              
              <a href="https://www.jasongt.com/projectpages/pipal.html">website</a> /
              
              
              <p></p>
              <p>This paper highlights the challenge IQA faces with emerging GAN-based image restoration methods, noting a growing disparity between quantitative metrics and perceptual quality. To address this, the authors introduce a large-scale IQA dataset and benchmarks to enhance IQA methods’ effectiveness.</p>

            </td>
          </tr>
          
          
          
          
          
          
          
          
          
          
          
        </table>




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h25>Controllable & Efficient Image Restoration (2020 - 2022)</h25>
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_22_SRPO.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Super-resolution by predicting offsets: An ultra-efficient super-resolution network for rasterized images</h3>
              <br>
              Jinjin Gu, <strong>Haoming Cai</strong>, Chenyu Dong, Ruofan Zhang, Yulun Zhang, Wenming Yang, Chun Yuan.

              <br>
              <em><strongvenue>ECCV'22</strongvenue></em>
              <br>
              
              <small><a href="https://arxiv.org/pdf/2210.04198">arxiv</a></small>/
              
              
              
              <a href="https://github.com/HaomingCai/SRPO">code</a> /
              
              
              
              
              
              <p></p>
              <p>SRPO is a real-time super-resolution method for computer graphics, achieving superior visual effects with minimal computational cost by leveraging rasterized image features and offset prediction.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_22_VapSR.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Efficient image super-resolution using vast-receptive-field attention</h3>
              <br>
              <strong>Haoming Cai*</strong>, Lin Zhou*, Jinjin Gu, Zheyuan Li, Yingqi Liu, Xiangyu Chen, Yu Qiao, Chao .

              <br>
              <em><strongvenue>AIM'22 @ ECCV</strongvenue></em>
              <br>
              
              <small><a href="https://arxiv.org/pdf/2210.05960">arxiv</a></small>/
              
              
              
              <a href="https://github.com/zhoumumu/VapSR">code</a> /
              
              
              
              
              
              <p></p>
              <p>This study improves super-resolution networks by refining the attention mechanism, leading to VapSR, which outperforms lightweight networks with fewer parameters, achieving similar results as IMDB and RFDN networks with significantly fewer parameters.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_22_BSRN.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Blueprint separable residual network for efficient image super-resolution</h3>
              <br>
              Zheyuan Li, Yingqi Liu, Xiangyu Chen, <strong>Haoming Cai</strong>, Jinjin Gu, Yu Qiao, Chao Dong.

              <br>
              <em><strongvenue>NTIRE'23 @ CVPR</strongvenue></em>
              <br>
              
              <small><a href="https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Li_Blueprint_Separable_Residual_Network_for_Efficient_Image_Super-Resolution_CVPRW_2022_paper.pdf">arxiv</a></small>/
              
              
              
              <a href="https://github.com/xiaom233/BSRN">code</a> /
              
              
              
              
              
              <p></p>
              <p>Winner of Efficient Image Super-Resolution Track @ New Trends in Image Restoration and Enhancement (NTIRE) workshop of CVPR’23</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_21_CUGAN.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Toward interactive modulation for photo-realistic image restoration</h3>
              <br>
              <strong>Haoming Cai</strong>, Jingwen He, Yu Qiao, Chao Dong.

              <br>
              <em><strongvenue>CVPRW'21</strongvenue></em>
              <br>
              
              <small><a href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Cai_Toward_Interactive_Modulation_for_Photo-Realistic_Image_Restoration_CVPRW_2021_paper.pdf">arxiv</a></small>/
              
              
              
              <a href="https://github.com/HaomingCai/CUGAN">code</a> /
              
              
              
              
              
              <p></p>
              <p>This paper presents CUGAN, a Controllable Unet GAN, for modulating image restoration tasks with fine texture details. Through dynamic level adjustments and condition networks, CUGAN outperforms previous methods, offering smooth user control over output effects.</p>

            </td>
          </tr>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </table>




























        <!-- <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Other Projects</h2>
              <p> These include coursework, side projects and unpublished research work. 
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Illumination Director: Lighting Customization on Generated Portrait in Text-2-Image Diffusion Model</h3>
              <br>
              <em>ComputationalPhotography </em>
              <br>
              2023-08-09

              <br>
              
              
              
              
              
              
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Illumination Director: Lighting Customization on Generated Portrait in Text-2-Image Diffusion Model</h3>
              <br>
              <em>ComputationalPhotography </em>
              <br>
              2023-08-09

              <br>
              
              
              
              
              
              
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_23_ConVRT.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Temporally Consistent Atmospheric Turbulence Mitigation with Neural Representations</h3>
              <br>
              <em>AdverseWeather </em>
              <br>
              2023-08-09

              <br>
              
              
              
              
              
              
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_24_Flash.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Flash-Splat: 3D Reflection Removal with Flash Cues and Gaussian Splats</h3>
              <br>
              <em>AdverseWeather </em>
              <br>
              2023-08-09

              <br>
              
              <a href="https://flash-splat.github.io/">website</a> /
              
              
              
              
              
              
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_24_Event.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>TimeRewind: Rewinding Time with Image-and-Events Video Diffusion</h3>
              <br>
              <em>GenAI </em>
              <br>
              2023-08-09

              <br>
              
              
              
              
              
              
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_23_PSF.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>CodedEvents: Optimal Point-Spread-Function Engineering for 3D-Tracking with Event Cameras</h3>
              <br>
              <em>AdverseWeather </em>
              <br>
              2023-08-09

              <br>
              
              
              
              
              
              
              
              
              
              
              <p></p>
              <p>This paper explores PSF engineering for neuromorphic event cameras, designing optimized masks for superior 3D point localization and tracking.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_23_OBIQA.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Assessor360: Multi-sequence Network for Blind Omnidirectional Image Quality Assessment</h3>
              <br>
              <em>IQA </em>
              <br>
              2023-08-09

              <br>
              
              <a href="https://github.com/TianheWu/Assessor360">website</a> /
              
              
              
              
              
              
              
              
              <a href="https://github.com/TianheWu/Assessor360">code</a> /
              
              
              
              <p></p>
              <p>Current omnidirectional image quality assessment lacks observer browsing modeling. We propose Assessor360, a novel multi-sequence network for BOIQA derived from realistic multi-assessor ODI quality assessment</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_23_Snow.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Snow Removal in Video: A New Dataset and A Novel Method</h3>
              <br>
              <em>AdverseWeather </em>
              <br>
              2023-08-09

              <br>
              
              <a href="https://haoyuchen.com/VideoDesnowing">website</a> /
              
              
              
              
              
              
              
              
              <a href="https://github.com/haoyuc/VideoDesnowing">code</a> /
              
              
              
              <p></p>
              <p>This paper presents a new deep learning framework for removing snow from videos, featuring a high-quality dataset and innovative modules for effective snow removal, outperforming existing methods.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_22_SRPO.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Super-resolution by predicting offsets: An ultra-efficient super-resolution network for rasterized images</h3>
              <br>
              <em>SR </em>
              <br>
              2023-08-09

              <br>
              
              
              
              
              
              
              
              
              <a href="https://github.com/HaomingCai/SRPO">code</a> /
              
              
              
              <p></p>
              <p>SRPO is a real-time super-resolution method for computer graphics, achieving superior visual effects with minimal computational cost by leveraging rasterized image features and offset prediction.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_22_VapSR.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Efficient image super-resolution using vast-receptive-field attention</h3>
              <br>
              <em>SR </em>
              <br>
              2023-08-09

              <br>
              
              
              
              
              
              
              
              
              <a href="https://github.com/zhoumumu/VapSR">code</a> /
              
              
              
              <p></p>
              <p>This study improves super-resolution networks by refining the attention mechanism, leading to VapSR, which outperforms lightweight networks with fewer parameters, achieving similar results as IMDB and RFDN networks with significantly fewer parameters.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_22_BSRN.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Blueprint separable residual network for efficient image super-resolution</h3>
              <br>
              <em>SR </em>
              <br>
              2023-08-09

              <br>
              
              
              
              
              
              
              
              
              <a href="https://github.com/xiaom233/BSRN">code</a> /
              
              
              
              <p></p>
              <p>Winner of Efficient Image Super-Resolution Track @ New Trends in Image Restoration and Enhancement (NTIRE) workshop of CVPR’23</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_21_CUGAN.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Toward interactive modulation for photo-realistic image restoration</h3>
              <br>
              <em>SR </em>
              <br>
              2023-08-09

              <br>
              
              
              
              
              
              
              
              
              <a href="https://github.com/HaomingCai/CUGAN">code</a> /
              
              
              
              <p></p>
              <p>This paper presents CUGAN, a Controllable Unet GAN, for modulating image restoration tasks with fine texture details. Through dynamic level adjustments and condition networks, CUGAN outperforms previous methods, offering smooth user control over output effects.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/00_Pub_20_PIPAL.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Pipal: a large-scale image quality assessment dataset for perceptual image restoration</h3>
              <br>
              <em>IQA </em>
              <br>
              2023-08-09

              <br>
              
              <a href="https://www.jasongt.com/projectpages/pipal.html">website</a> /
              
              
              
              
              
              
              
              
              
              
              <p></p>
              <p>This paper highlights the challenge IQA faces with emerging GAN-based image restoration methods, noting a growing disparity between quantitative metrics and perceptual quality. To address this, the authors introduce a large-scale IQA dataset and benchmarks to enhance IQA methods’ effectiveness.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/dequant.jpg" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Dequantization of Depth Data</h3>
              <br>
              <em>None </em>
              <br>
              2015-04-22

              <br>
              
              
              
              
              
              
              
              
              <a href="https://github.com/leonidk/qInterp">code</a> /
              
              
              
              <p></p>
              <p>An O(1) time algorithm for producing smooth normals for quantized data, such as the Kinect.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/box.jpg" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Real-time Box Measurement</h3>
              <br>
              <em>None </em>
              <br>
              2015-04-08

              <br>
              
              
              
              
              
              
              <a href="https://www.youtube.com/watch?v=ZZvZVaBFpYE">video</a> /
              
              
              <a href="https://www.youtube.com/watch?v=rYnFWkF7Jx8">video #2</a> /
              
              
              
              
              <p></p>
              <p>Using a single depth sensor, real-time detection of cuboids, accurate estimation of their dimensions, and even some bin-packing.</p>

            </td>
          </tr>
          
          
          
        </table> -->



<!-- 
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                I am really grateful to my cat (千金 / Qianjin) for her unconditional love and support.
              </p>
            </td>
          </tr>
        </table> -->




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>


  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=0e1633&w=100&t=tt&d=QROiebfOxQKem7OOPCmt05uBYxlc-Sm4CCGIwz8gsCk&co=0b4975&cmo=3acc3a&cmn=ff5353&ct=cdd4d9'></script>

</body>

</html>

